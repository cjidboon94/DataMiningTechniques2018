{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 10, 11, 12, 13, 14, 15]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n"
     ]
    },
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/s1924192/DataMiningTechniques2018/Ass1/data_rnn/fold_1/train/AS14.12.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-de4a485645ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'indexje'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~/DataMiningTechniques2018/Ass1/data_rnn/fold_{}/train/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mtest_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'~/DataMiningTechniques2018/Ass1/data_rnn/fold_{}/test/{}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/s1924192/anaconda2/lib/python2.7/site-packages/pandas/core/frame.pyc\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1401\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1402\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1403\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1404\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/s1924192/anaconda2/lib/python2.7/site-packages/pandas/io/formats/format.pyc\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1575\u001b[0m             f, handles = _get_handle(self.path_or_buf, self.mode,\n\u001b[1;32m   1576\u001b[0m                                      \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1577\u001b[0;31m                                      compression=self.compression)\n\u001b[0m\u001b[1;32m   1578\u001b[0m             \u001b[0mclose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1579\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/s1924192/anaconda2/lib/python2.7/site-packages/pandas/io/common.pyc\u001b[0m in \u001b[0;36m_get_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPY2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;31m# Python 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;31m# Python 3 and encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/s1924192/DataMiningTechniques2018/Ass1/data_rnn/fold_1/train/AS14.12.csv'"
     ]
    }
   ],
   "source": [
    "# create RNN data\n",
    "\n",
    "datafilestrain1 = os.listdir('data_complete')\n",
    "datafiles = [a for a in datafilestrain1 if a.startswith('AS')]\n",
    "datafiles.remove('AS14.32.csv')\n",
    "\n",
    "################\n",
    "\n",
    "window=1\n",
    "\n",
    "for user in datafiles:\n",
    "    for fold in [1,2,3,4]:\n",
    "        train_dataset  = pd.read_csv('data_complete/fold_{}/train/{}'.format(fold, user))\n",
    "        test_dataset = pd.read_csv('data_complete/fold_{}/test/'.format(fold) + user)\n",
    "\n",
    "        test_indices = list(test_dataset['Unnamed: 0'])\n",
    "        print test_indices\n",
    "        train_indices = list(train_dataset['Unnamed: 0'])\n",
    "        print train_indices\n",
    "\n",
    "        df = pd.concat([train_dataset, test_dataset])\n",
    "        df = df.sort_values('Unnamed: 0')\n",
    "\n",
    "        normalized_test_df = pd.read_csv('data_normalized/fold_{}/test/{}'.format(fold, user))\n",
    "        normalized_train_df = pd.read_csv('data_normalized/fold_{}/train/{}'.format(fold, user))\n",
    "        vars1 = list(normalized_train_df.columns)\n",
    "        #print vars1\n",
    "        vars1.remove('Unnamed: 0')\n",
    "        vars2 = ['predict_day', 'user', 'window', 'true_mood', 'indexje']\n",
    "        cols=vars2+vars1\n",
    "\n",
    "        dataset_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "        days = list(df['Unnamed: 0.1'])\n",
    "        for i in range(len(df)):\n",
    "            if i + window <= len(df) - 1:\n",
    "                windowstart = days[i]\n",
    "                windowend = days[i+window-1]\n",
    "                predictday = days[i+window]\n",
    "\n",
    "                avg_mood = df[i:i+window]['mood']\n",
    "                avg_arousal = df[i:i+window]['arousal']\n",
    "                avg_valence = df[i:i+window]['valence']\n",
    "                avg_activity = df[i:i+window]['activity']\n",
    "\n",
    "                normalized_row = normalized_test_df.loc[normalized_test_df['Unnamed: 0'] == days[i]]\n",
    "                if normalized_row.empty:\n",
    "                    normalized_row = normalized_train_df.loc[normalized_train_df['Unnamed: 0'] == days[i]]\n",
    "\n",
    "                vardict = {}\n",
    "                for var in vars1:\n",
    "                    vardict['predict_day'] = predictday\n",
    "                    vardict['mood'] = float(avg_mood)\n",
    "                    vardict['arousal'] = float(avg_arousal)\n",
    "                    vardict['valence'] = float(avg_valence)\n",
    "                    vardict['activity'] = float(avg_activity)\n",
    "                    vardict['true_mood'] = list(df['mood'])[i+window]\n",
    "                    vardict['indexje'] = list(df['Unnamed: 0'])[i]\n",
    "                    vardict['user'] = user[:-4]\n",
    "                    vardict['window'] = '{}-{}'.format(windowstart, windowend)\n",
    "                    if var not in ['mood', 'arousal', 'valence', 'activity', 'Unnamed: 0']:\n",
    "                        vardict[var] = float(normalized_row[var])\n",
    "\n",
    "                dataset_df = dataset_df.append(vardict, ignore_index=True)\n",
    "\n",
    "        dataset_df.indexje = dataset_df.indexje.astype(int)\n",
    "        dataset_df.index = dataset_df['indexje']\n",
    "\n",
    "        test_data = dataset_df.loc[[a-window for a in test_indices]]\n",
    "        train_data = dataset_df.loc[[a-window for a in train_indices]]\n",
    "\n",
    "        train_data = train_data[pd.notnull(train_data['predict_day'])]\n",
    "        test_data = test_data[pd.notnull(test_data['predict_day'])]\n",
    "        train_data = train_data.drop('indexje', axis=1)\n",
    "        test_data = test_data.drop('indexje', axis=1)\n",
    "\n",
    "        train_data.to_csv('~/DataMiningTechniques2018/Ass1/data_rnn/fold_{}/train/{}'.format(fold, user), index=False)\n",
    "        test_data.to_csv('~/DataMiningTechniques2018/Ass1/data_rnn/fold_{}/test/{}'.format(fold, user), index=False)\n",
    "        \n",
    "        print user, fold\n",
    "\n",
    "\n",
    "def create_dataset(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back):\n",
    "        a = dataset[i:(i+look_back)]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back])\n",
    "    return dataX, dataY\n",
    "\n",
    "look_back = 1\n",
    "\n",
    "def reshape_etc(data):\n",
    "    size = len(data)\n",
    "    data = np.array(data).reshape(size, 1)\n",
    "    return data\n",
    "\n",
    "trainX, trainY = create_dataset(np.array(train['mood']), look_back)\n",
    "testX, testY = create_dataset(np.array(test['mood']), look_back)\n",
    "\n",
    "valence_train_X, valence_train_Y = create_dataset(np.array(train['valence']), look_back)\n",
    "arousal_train_X, arousal_train_Y = create_dataset(np.array(train['arousal']), look_back)\n",
    "activity_train_X, activity_train_Y = create_dataset(np.array(train['activity']), look_back)\n",
    "\n",
    "valence_test_X, valence_test_Y = create_dataset(np.array(test['valence']), look_back)\n",
    "arousal_test_X, arousal_test_Y = create_dataset(np.array(test['arousal']), look_back)\n",
    "activity_test_X, activity_test_Y = create_dataset(np.array(test['activity']), look_back)\n",
    "\n",
    "trainX, trainY = reshape_etc(trainX), reshape_etc(trainY)\n",
    "valence_train_X = reshape_etc(valence_train_X)\n",
    "arousal_train_X = reshape_etc(arousal_train_X)\n",
    "activity_train_X = reshape_etc(activity_train_X)\n",
    "valence_test_X = reshape_etc(valence_test_X)\n",
    "arousal_test_X = reshape_etc(arousal_test_X)\n",
    "activity_test_X = reshape_etc(activity_test_X)\n",
    "\n",
    "trainX = np.column_stack((trainX, valence_train_X, arousal_train_X, activity_train_X))\n",
    "testX = np.column_stack((testX, valence_test_X, arousal_test_X, activity_test_X))     \n",
    " \n",
    "trainX = np.reshape(trainX, (trainX.shape[0], 1, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], 1, testX.shape[1]))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "trainY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4\"\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "model.fit(trainX, trainY, epochs=100, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 9, 10, 11, 12, 13, 14, 15]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]\n",
      "        predict_day     user                 window  mood  arousal   valence  \\\n",
      "indexje                                                                        \n",
      "0        2014-03-28  AS14.12  2014-03-27-2014-03-27  7.00    -0.50  1.000000   \n",
      "1        2014-03-29  AS14.12  2014-03-28-2014-03-28  6.75     0.00  0.750000   \n",
      "2        2014-03-30  AS14.12  2014-03-29-2014-03-29  6.75     1.00  1.000000   \n",
      "3        2014-03-31  AS14.12  2014-03-30-2014-03-30  5.80    -0.20  0.250000   \n",
      "4        2014-04-01  AS14.12  2014-03-31-2014-03-31  6.40     0.40  0.400000   \n",
      "5        2014-04-02  AS14.12  2014-04-01-2014-04-01  6.40     0.40  0.750000   \n",
      "6        2014-04-03  AS14.12  2014-04-02-2014-04-02  6.00    -0.40  0.333333   \n",
      "15       2014-04-12  AS14.12  2014-04-11-2014-04-11  6.60    -0.50  1.000000   \n",
      "16       2014-04-13  AS14.12  2014-04-12-2014-04-12  6.80     0.00  0.800000   \n",
      "17       2014-04-14  AS14.12  2014-04-13-2014-04-13  5.60     0.60  0.000000   \n",
      "18       2014-04-15  AS14.12  2014-04-14-2014-04-14  6.60    -0.40  0.800000   \n",
      "19       2014-04-16  AS14.12  2014-04-15-2014-04-15  6.80     0.20  1.000000   \n",
      "20       2014-04-17  AS14.12  2014-04-16-2014-04-16  7.00     0.00  1.000000   \n",
      "21       2014-04-18  AS14.12  2014-04-17-2014-04-17  6.80    -0.60  0.800000   \n",
      "22       2014-04-19  AS14.12  2014-04-18-2014-04-18  6.60    -0.60  0.800000   \n",
      "23       2014-04-20  AS14.12  2014-04-19-2014-04-19  5.80     0.40  0.400000   \n",
      "24       2014-04-21  AS14.12  2014-04-20-2014-04-20  6.40     0.40  1.000000   \n",
      "25       2014-04-22  AS14.12  2014-04-21-2014-04-21  6.00    -0.25  0.750000   \n",
      "26       2014-04-23  AS14.12  2014-04-22-2014-04-22  6.50     0.25  1.000000   \n",
      "27       2014-04-24  AS14.12  2014-04-23-2014-04-23  5.80     0.00  0.800000   \n",
      "28       2014-04-25  AS14.12  2014-04-24-2014-04-24  6.60    -0.60  0.600000   \n",
      "29       2014-04-26  AS14.12  2014-04-25-2014-04-25  5.60     0.20  0.200000   \n",
      "30       2014-04-27  AS14.12  2014-04-26-2014-04-26  7.00     0.25  1.000000   \n",
      "31       2014-04-28  AS14.12  2014-04-27-2014-04-27  6.00     0.00  0.750000   \n",
      "32       2014-04-29  AS14.12  2014-04-28-2014-04-28  6.60    -0.60  1.000000   \n",
      "33       2014-04-30  AS14.12  2014-04-29-2014-04-29  6.00    -0.40  1.000000   \n",
      "34       2014-05-01  AS14.12  2014-04-30-2014-04-30  6.25    -0.25  0.666667   \n",
      "35       2014-05-02  AS14.12  2014-05-01-2014-05-01  6.20    -0.20  0.500000   \n",
      "36       2014-05-03  AS14.12  2014-05-02-2014-05-02  5.50     0.00  0.500000   \n",
      "37       2014-05-04  AS14.12  2014-05-03-2014-05-03  5.60    -0.40  0.200000   \n",
      "38       2014-05-05  AS14.12  2014-05-04-2014-05-04  4.80    -0.80 -0.200000   \n",
      "\n",
      "         activity  true_mood  \n",
      "indexje                       \n",
      "0        0.148291       6.75  \n",
      "1        0.112189       6.75  \n",
      "2        0.126075       5.80  \n",
      "3        0.050003       6.40  \n",
      "4        0.072546       6.40  \n",
      "5        0.140792       6.00  \n",
      "6        0.147060       5.40  \n",
      "15       0.071511       6.80  \n",
      "16       0.084032       5.60  \n",
      "17       0.095383       6.60  \n",
      "18       0.087424       6.80  \n",
      "19       0.120050       7.00  \n",
      "20       0.198099       6.80  \n",
      "21       0.131062       6.60  \n",
      "22       0.079979       5.80  \n",
      "23       0.167165       6.40  \n",
      "24       0.220267       6.00  \n",
      "25       0.070231       6.50  \n",
      "26       0.164627       5.80  \n",
      "27       0.114494       6.60  \n",
      "28       0.085223       5.60  \n",
      "29       0.134679       7.00  \n",
      "30       0.332577       6.00  \n",
      "31       0.193479       6.60  \n",
      "32       0.085398       6.00  \n",
      "33       0.079198       6.25  \n",
      "34       0.121993       6.20  \n",
      "35       0.095570       5.50  \n",
      "36       0.131000       5.60  \n",
      "37       0.085140       4.80  \n",
      "38       0.114599       6.00  \n",
      "        predict_day     user                 window  mood  arousal   valence  \\\n",
      "indexje                                                                        \n",
      "7        2014-04-04  AS14.12  2014-04-03-2014-04-03  5.40     0.40  0.000000   \n",
      "8        2014-04-05  AS14.12  2014-04-04-2014-04-04  6.50     0.75  0.666667   \n",
      "9        2014-04-06  AS14.12  2014-04-05-2014-04-05  6.20     0.00  0.400000   \n",
      "10       2014-04-07  AS14.12  2014-04-06-2014-04-06  6.25     0.25  0.750000   \n",
      "11       2014-04-08  AS14.12  2014-04-07-2014-04-07  6.40     0.20  1.000000   \n",
      "12       2014-04-09  AS14.12  2014-04-08-2014-04-08  6.25     0.00  0.250000   \n",
      "13       2014-04-10  AS14.12  2014-04-09-2014-04-09  5.25     0.00 -0.500000   \n",
      "14       2014-04-11  AS14.12  2014-04-10-2014-04-10  6.40     0.20  0.600000   \n",
      "\n",
      "         activity  true_mood  \n",
      "indexje                       \n",
      "7        0.157341       6.50  \n",
      "8        0.138780       6.20  \n",
      "9        0.150298       6.25  \n",
      "10       0.087211       6.40  \n",
      "11       0.125655       6.25  \n",
      "12       0.117655       5.25  \n",
      "13       0.165517       6.40  \n",
      "14       0.133821       6.60  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "fold = 1\n",
    "\n",
    "trainfiles = os.listdir('data_complete/fold_{}/train'.format(1))\n",
    "testfiles = os.listdir('data_complete/fold_{}/test'.format(1))\n",
    "\n",
    "try:\n",
    "    trainfiles.remove('AS14.32.csv')\n",
    "    testfiles.remove('AS14.32.csv')\n",
    "except:\n",
    "    pass\n",
    "    \n",
    "for user in [trainfiles[0]]:\n",
    "    for fold in [[1, 2, 3, 4][0]]:\n",
    "        for window in [1]:\n",
    "            train_dataset  = pd.read_csv('data_complete/fold_{}/train/'.format(fold) + user)\n",
    "            test_dataset = pd.read_csv('data_complete/fold_{}/test/'.format(fold) + user)\n",
    "\n",
    "            test_indices = list(test_dataset['Unnamed: 0'])\n",
    "            print test_indices\n",
    "            train_indices = list(train_dataset['Unnamed: 0'])\n",
    "            print train_indices\n",
    "\n",
    "            df = pd.concat([train_dataset, test_dataset])\n",
    "            df = df.sort_values('Unnamed: 0')\n",
    "\n",
    "            dataset_df = pd.DataFrame(columns=['predict_day', 'user', 'window', 'mood', 'arousal', \\\n",
    "                                                   'valence', 'activity', 'true_mood', 'indexje'])\n",
    "\n",
    "            #print df\n",
    "            days = list(df['Unnamed: 0.1'])\n",
    "            for i in range(len(df)):\n",
    "                if i + window <= len(df) - 1:\n",
    "                    windowstart = days[i]\n",
    "                    windowend = days[i+window-1]\n",
    "                    predictday = days[i+window]\n",
    "\n",
    "                    avg_mood = df[i:i+window]['mood'].mean()\n",
    "                    avg_arousal = df[i:i+window]['arousal'].mean()\n",
    "                    avg_valence = df[i:i+window]['valence'].mean()\n",
    "                    avg_activity = df[i:i+window]['activity'].mean()\n",
    "\n",
    "                    dataset_df = dataset_df.append({'predict_day': predictday, 'user': user[:-4], 'window': '{}-{}'.format(windowstart, \\\n",
    "                                                     windowend), 'mood': avg_mood, 'arousal': avg_arousal, \\\n",
    "                                                     'valence': avg_valence, 'activity': avg_activity, \\\n",
    "                                                     'true_mood': list(df['mood'])[i+window], 'indexje': list(df['Unnamed: 0'])[i]}, ignore_index=True)\n",
    "\n",
    "            dataset_df.indexje = dataset_df.indexje.astype(int)\n",
    "            dataset_df.index = dataset_df['indexje']\n",
    "\n",
    "            test_data = dataset_df.loc[[a-window for a in test_indices]]\n",
    "            train_data = dataset_df.loc[[a-window for a in train_indices]]\n",
    "\n",
    "            train_data = train_data[pd.notnull(train_data['predict_day'])]\n",
    "            test_data = test_data[pd.notnull(test_data['predict_day'])]\n",
    "            train_data = train_data.drop('indexje', axis=1)\n",
    "            test_data = test_data.drop('indexje', axis=1)\n",
    "            #train_data.to_csv('interval_datasets/window_{}/fold_{}/train/{}'.format(window, fold, user), index=False)\n",
    "            #test_data.to_csv('interval_datasets/window_{}/fold_{}/test/{}'.format(window, fold, user), index=False)\n",
    "            print train_data\n",
    "            print test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
